{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickbait Spoiler Generation using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary to fix the imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"distilbert-base-uncased-distilled-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "SAVE_CHECKPOINT_PATH = \"../src/models/bert/clickbait\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ddsantos/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ddsantos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ddsantos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ddsantos/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-uncased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from utils.bert import MODEL_CHECKPOINT, TOKENIZER\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c436ff332249223c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset clickbait_data/default to /Users/ddsantos/.cache/huggingface/datasets/clickbait_data/default-c436ff332249223c/0.0.0/264c21381577df7a68b078d3233557c5c51acba80b028ef1987ae9ae6d00581a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 3/3 [00:00<00:00, 10565.00it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset clickbait_data downloaded and prepared to /Users/ddsantos/.cache/huggingface/datasets/clickbait_data/default-c436ff332249223c/0.0.0/264c21381577df7a68b078d3233557c5c51acba80b028ef1987ae9ae6d00581a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 394.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"../data/parsed/bert/clickbait_data.py\", data_files={\n",
    "    \"train\": \"train.jsonl\", \n",
    "    \"test\": \"test.jsonl\", \n",
    "    \"validation\": \"validation.jsonl\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.46s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3200, 9056)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.bert\n",
    "\n",
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    utils.bert.preprocess_training,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(602, 1721)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = raw_datasets[\"test\"].map(\n",
    "    utils.bert.preprocess_validation,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"test\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"test\"]), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.18ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(198, 623)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    utils.bert.preprocess_validation,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    train_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_steps = len(tf_train_dataset) * N_EPOCHS\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=LEARNING_RATE,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=\"../src/models/bert/checkpoints/model.{epoch:02d}_{accuracy:.2f}-{loss:.2f}_{val_accuracy:.2f}-{val_loss:.2f}.h5\"),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"../src/models/bert/logs\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 05:12:15.175857: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    callbacks=callbacks,\n",
    "    epochs=N_EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(SAVE_CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_dataset = model.prepare_tf_dataset(\n",
    "    test_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.bert.compute_metrics(\n",
    "    predictions[\"start_logits\"],\n",
    "    predictions[\"end_logits\"],\n",
    "    validation_dataset,\n",
    "    raw_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=SAVE_CHECKPOINT_PATH, tokenizer=TOKENIZER)\n",
    "\n",
    "context = \"\"\"\n",
    "At some point toward the end of every job interview, the hiring manager will likely turn the tables and ask, \\\"Do you have any questions for me?\\\"\\nThis is the time to ask smart, thoughtful questions — perhaps your final opportunity to assess whether the job would be a good fit, and your final chance to impress the hiring manager.\\nBusiness Insider recently spoke with Becca Brown, cofounder of Solemates, a brand of women's shoe-care products, who knows a thing or two about interviewing.\\nBefore launching her own business, Brown, who has a bachelor's from Harvard University and an MBA from Columbia, spent a lot of time interviewing job candidates at Goldman Sachs, where she held various roles, including analyst, wealth adviser, and chief of staff.\\nShe was also part of the investment bank's Harvard recruiting team, she says.\\n\\\"I interviewed anywhere from 20 to 30 job candidates a year, so in total, I interviewed over 100 people at Goldman Sachs,\\\" she tells Business Insider.\\nShe says that candidates asked her some impressive questions — like \\\"What's the most challenging part of your job?\\\" and \\\"What's one of the most interesting projects you've worked on?\\\" — but there was one question she always hoped she'd be asked, but almost never was: \\\"Where do you see yourself in five years?\\\"\\n\\\"I like this question — and yet no one ever asked it — because it's difficult to answer,\\\" she says. \\\"It's an important question for anyone to be asking him or herself, and so if ever a candidate were to ask this question, it would have stood out.\\\"\\nShe continues:\\nI think this is a good question for interviewees to ask because, as a candidate, if you see where the person interviewing you is headed, you can decide if that trajectory is in line with your career objectives. While they don't have to be completely correlated, it's helpful for the candidate to have some indication of the interviewer's direction.\\nGet the latest Goldman Sachs stock price here.\n",
    "\"\"\"\n",
    "question=\"A woman who interviewed over 100 people at Goldman Sachs says there's one question she always hoped candidates would ask her, but they never did\"\n",
    "expected = \"\\\"Where do you see yourself in five years?\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = question_answerer(question=question, context=context)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "# bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_results = meteor.compute(predictions=[prediction[\"answer\"]], references=[expected])\n",
    "bleu_results = bleu.compute(predictions=[prediction[\"answer\"]], references=[expected])\n",
    "# bertscore_results = bertscore.compute(predictions=prediction, references=expected, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{question};\\n\\nExpected Spoiler: {expected};\\n\\nSpoiler Predicted: {prediction['answer']};\\n\\n###\\n\\n\")\n",
    "print(f\"Meteor: {meteor_results['meteor']}\\nBLEU-4: {bleu_results['bleu']}\")\n",
    "# print(f\"Meteor: {meteor_results['meteor']}\\nBLEU-4: {bleu_results['bleu']}\\nBERTscore Mean F1: {sum(bertscore_results['f1'])/len(bertscore_results['f1'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
