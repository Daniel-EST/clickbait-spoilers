{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary to fix the imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TRAIN_DATA = \"../data/train.jsonl\"\n",
    "ORIGINAL_VALIDATION_DATA = \"../data/validation.jsonl\"\n",
    "\n",
    "SPLIT_FOLDER = \"../data/splitted\"\n",
    "\n",
    "TRAIN_DATA = f\"{SPLIT_FOLDER}/train.jsonl\"\n",
    "VALIDATION_DATA = f\"{SPLIT_FOLDER}/validation.jsonl\"\n",
    "TEST_DATA = f\"{SPLIT_FOLDER}/test.jsonl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data using a custom function and validating it using the openai preparation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(input=ORIGINAL_VALIDATION_DATA, output=SPLIT_FOLDER, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/splitted/train.jsonl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copyfile(ORIGINAL_TRAIN_DATA, TRAIN_DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"ada\"\n",
    "OPENAI_TRAIN_DATA = \"../data/parsed/openai/train.jsonl\"\n",
    "OPENAI_TEST_DATA = \"../data/parsed/openai/test.jsonl\"\n",
    "OPENAI_VALIDATION_DATA = \"../data/parsed/openai/validation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 3200 prompt-completion pairs\n",
      "- There are 3 duplicated prompt-completion sets. These are rows: [1248, 2315, 2698]\n",
      "- There are 1 examples that are very long. These are rows: [2594]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All prompts start with prefix `CLICKBAIT:\n",
      "\n",
      "`\n",
      "- All completions end with suffix ` END`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 3 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Remove 1 long examples [Y/n]: Y\n",
      "The indices of the long examples has changed as a result of a previously applied recommendation.\n",
      "The 1 long examples to be dropped are now at the following indices: [2592]\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `../data/parsed/openai/train_prepared (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../data/parsed/openai/train_prepared (1).jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 3.03 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "prepare_data_openai.prepare(input=TRAIN_DATA, output=OPENAI_TRAIN_DATA, model=OPENAI_MODEL, validation=False)\n",
    "!openai tools fine_tunes.prepare_data --file $OPENAI_TRAIN_DATA --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 602 prompt-completion pairs\n",
      "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['id', 'type']\n",
      "  WARNING: Some of the additional columns/keys contain `id` in their name. These will be ignored, and the column/key `id` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
      "  WARNING: Some of the additional columns/keys contain `type` in their name. These will be ignored, and the column/key `type` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All prompts start with prefix `CLICKBAIT:\n",
      "\n",
      "`\n",
      "- All completions end with suffix ` END`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Remove additional columns/keys: ['id', 'type']\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `../data/parsed/openai/test_prepared (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../data/parsed/openai/test_prepared (1).jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 10.71 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "prepare_data_openai.prepare(input=TEST_DATA, output=OPENAI_TEST_DATA, model=OPENAI_MODEL, validation=True)\n",
    "!openai tools fine_tunes.prepare_data --file $OPENAI_TEST_DATA --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 198 prompt-completion pairs\n",
      "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['id', 'type']\n",
      "  WARNING: Some of the additional columns/keys contain `id` in their name. These will be ignored, and the column/key `id` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
      "  WARNING: Some of the additional columns/keys contain `type` in their name. These will be ignored, and the column/key `type` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All prompts start with prefix `CLICKBAIT:\n",
      "\n",
      "`\n",
      "- All completions end with suffix ` END`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Remove additional columns/keys: ['id', 'type']\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `../data/parsed/openai/validation_prepared (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../data/parsed/openai/validation_prepared (1).jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 5.17 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "prepare_data_openai.prepare(input=VALIDATION_DATA, output=OPENAI_VALIDATION_DATA, model=OPENAI_MODEL, validation=True)\n",
    "!openai tools fine_tunes.prepare_data --file $OPENAI_VALIDATION_DATA --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_TRAIN_DATA = \"../data/parsed/bert/train.jsonl\"\n",
    "BERT_TEST_DATA = \"../data/parsed/bert/test.jsonl\"\n",
    "BERT_VALIDATION_DATA = \"../data/parsed/bert/validation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_bert.prepare(input=TRAIN_DATA, output=BERT_TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_bert.prepare(input=TEST_DATA, output=BERT_TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_bert.prepare(input=VALIDATION_DATA, output=BERT_VALIDATION_DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_TRAIN_DATA = \"../data/parsed/llama/train.jsonl\"\n",
    "LLAMA_TEST_DATA = \"../data/parsed/llama/test.jsonl\"\n",
    "LLAMA_VALIDATION_DATA = \"../data/parsed/llama/validation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_llama.prepare(input=TRAIN_DATA, output=LLAMA_TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_llama.prepare(input=TEST_DATA, output=LLAMA_TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_llama.prepare(input=VALIDATION_DATA, output=LLAMA_VALIDATION_DATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
